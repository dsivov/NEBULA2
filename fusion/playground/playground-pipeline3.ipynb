{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4422f0-1ada-4324-8173-2fb89a605b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import bisect\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib\n",
    "import subprocess\n",
    "import re\n",
    "import tempfile\n",
    "import itertools\n",
    "import torch\n",
    "import spacy\n",
    "import amrlib\n",
    "import penman\n",
    "\n",
    "from typing import List, Tuple\n",
    "from operator import itemgetter \n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification\n",
    "# import qgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79742a6-1df7-40ae-aec8-c3a3960e81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.getcwd()+'/../..')  # /home/gil/dev/NEBULA2/\n",
    "os.chdir(os.getcwd()+'/../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41181f5b-01c9-4ff4-82bf-8819720dc6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nebula_api.nebula_enrichment_api import *\n",
    "from experts.common.RemoteAPIUtility import RemoteAPIUtility\n",
    "from nebula_api.vlmapi import VLM_API\n",
    "from nebula_api.atomic2020.comet_enrichment_api import *\n",
    "from nebula_api.canonisation_api import CANON_API\n",
    "import nebula_api.playground_api as pg_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd9364-8b09-4c79-9fdc-e9329d40e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nre = NRE_API()\n",
    "api = RemoteAPIUtility()\n",
    "vlm = VLM_API()\n",
    "# mdmmt = mdmmt_api.MDMMT_API()\n",
    "# comet = Comet(\"/app/NEBULA2/nebula_api/atomic2020/comet-atomic_2020_BART\")\n",
    "ascore = CANON_API()\n",
    "# stog = amrlib.load_stog_model(model_dir=\"/app/NEBULA2/models/model_stog\")\n",
    "# gtos = amrlib.load_gtos_model(model_dir=\"/app/NEBULA2/models/model_gtos\")\n",
    "# model_name = \"Alireza1044/albert-base-v2-cola\" \n",
    "\n",
    "\n",
    "# Download cola model\n",
    "# cola_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243e402-1e54-466f-bf5a-e930ccc6d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lst): return [x for l in lst for x in l]\n",
    "\n",
    "def compute_batch_scores(video_emb: torch.Tensor, texts: List[str], normalize=True, **kwargs) -> List[float]:    \n",
    "    emb_batch = vlm.encode_text(texts, **kwargs)\n",
    "    if type(emb_batch) == list:\n",
    "        emb_batch = torch.stack(emb_batch,axis=0)\n",
    "    if normalize:\n",
    "        video_emb = video_emb / video_emb.norm(2)\n",
    "        # print(\"normalized video norm: {}\".format(video_emb.norm(2)))\n",
    "        n = (emb_batch * emb_batch).sum(axis=1).sqrt()\n",
    "        emb_batch = emb_batch / n.unsqueeze(1).expand_as(emb_batch)\n",
    "        # print(\"normalized text norms:\")\n",
    "        # for emb in emb_batch:\n",
    "        #     print(emb.norm(2))                        \n",
    "    return (video_emb.unsqueeze(0).expand_as(emb_batch)*emb_batch).sum(dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "def compute_concat_score(image_emb: torch.Tensor, texts: List[str], join_on=',') -> float:\n",
    "    combined_text = \"\"\n",
    "    for t in [x.strip() for x in texts]:\n",
    "        if t[-1]=='.':\n",
    "            t = t[:-1]       \n",
    "        t+=join_on\n",
    "        t+=' '\n",
    "        combined_text+=t\n",
    "    print(\"Combined: \"+combined_text)\n",
    "    return torch.matmul(image_emb,mdmmt.encode_text(combined_text.strip()) )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992bc58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_concept(c):\n",
    "    exp = re.compile(r\"^([a-zA-z]+)-?(\\d*)$\")\n",
    "    r = exp.match(c)\n",
    "    return r.group(1) if r else c\n",
    "\n",
    "class ConceptManager:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def ground_concept(concept):\n",
    "        return transform_concept(concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5004e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimilarityManager:\n",
    "#     def __init__(self):\n",
    "#         self.nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "#     def similarity(self, c1, c2):\n",
    "#         if type(c2) is not list:\n",
    "#             c2 = [c2]   \n",
    "#         a = self.nlp(c1)\n",
    "#         targets = self.nlp(' '.join(c2))\n",
    "#         return [a.similarity(x) for x in targets]\n",
    "    \n",
    "class SimilarityManager:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "    def similarity(self, src, target):\n",
    "        rc = []\n",
    "        s1 = self.nlp(src)\n",
    "        s2 = self.nlp(target)\n",
    "        for w in s1:\n",
    "            if w.pos_ not in ['NOUN', 'ADJ', 'ADV', 'VERB', 'PROPN']:\n",
    "                continue\n",
    "            rc.append(max([w.similarity(x) for x in s2]))\n",
    "        return np.mean(rc)\n",
    "        \n",
    "smanager = SimilarityManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdc76c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "smanager.similarity(\"flowers in vase\",\"a man stands in the room near some flowers in a vase, and a cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = lambda x: np.exp(x)/sum(np.exp(x))\n",
    "\n",
    "class SubsetOptimization:\n",
    "    def __init__(self, video_emb, experts: List, candidates_strings: List[str], coverage_matrix = None):\n",
    "        self.video_emb = video_emb\n",
    "        self.initial_temp = 10\n",
    "        self.final_temp = .001\n",
    "        self.alpha = 0.01\n",
    "        self.theta = 0.5\n",
    "        self.reset_every = 5000\n",
    "        self.experts = experts\n",
    "        self.candidates_strings = candidates_strings\n",
    "        print(\"Computing batch similarity...\")\n",
    "        self.candidates_similarity = compute_batch_scores(self.video_emb, self.candidates_strings)\n",
    "        print(\"Done\")\n",
    "        self.opt_results = []\n",
    "        self.smanager = SimilarityManager()\n",
    "\n",
    "        if coverage_matrix is not None:\n",
    "            self.coverage_matrix = coverage_matrix\n",
    "        else:\n",
    "            self.coverage_matrix = np.zeros([len(self.experts),len(self.candidates_strings)])\n",
    "            self.coverage_matrix[:] = np.nan\n",
    "            for i in range(len(experts)):\n",
    "                for j in range(len(candidates_strings)):\n",
    "                    self.coverage_matrix[i][j]=self.concept_similarity(self.experts[i],self.candidates_strings[j])\n",
    "        self.max_size = int(len(self.experts)*1.5)\n",
    "\n",
    "    def concept_similarity(self, concept, sent):        \n",
    "        # return max(self.smanager.similarity(concept,sent))\n",
    "        return self.smanager.similarity(concept,sent)\n",
    "\n",
    "    def get_coverage(self,i,j):        \n",
    "        if np.isnan(self.coverage_matrix[i][j]):\n",
    "            self.coverage_matrix[i][j] = self.concept_similarity(self.experts[i],self.candidates_strings[j])\n",
    "        return self.coverage_matrix[i][j]\n",
    "\n",
    "    def get_expert_coverage(self,state):\n",
    "        return self.coverage_matrix[:,state].max(axis=1)\n",
    "\n",
    "    def get_state_coverage(self,state) -> float:\n",
    "        # print(\"State coverage for {}:\".format(state))\n",
    "        # print(self.get_expert_coverage(state))\n",
    "        return np.mean(self.get_expert_coverage(state))\n",
    "\n",
    "    # def get_state_coverage(self, state: List[int]) -> float:\n",
    "    #     experts_coverage = [max([self.get_coverage(i,j) for j in state]) for i in range(len(self.experts))]    # A list of partial coverege        \n",
    "    #     return sum(experts_coverage) / len(self.experts)\n",
    "\n",
    "    def get_score(self, state: List[int]) -> float:\n",
    "        if not state:\n",
    "            return 0\n",
    "        coverage_score = self.get_state_coverage(state)   \n",
    "        similarity_score = self.candidates_similarity[state].mean().item()\n",
    "        return (1-self.theta)*coverage_score + self.theta*similarity_score\n",
    "\n",
    "\n",
    "    def prob_to_remove(self, state):\n",
    "        cover = self.get_state_coverage(state)\n",
    "        return np.power(cover,4)\n",
    "        \n",
    "    # state here is assumed (and guaranteed on return) to be -sorted-\n",
    "    def get_candidate(self, state: List[int]) -> List[int]:\n",
    "        def compute_state_arrays(s):\n",
    "            s_score = self.candidates_similarity[s]\n",
    "            s_coverage = self.coverage_matrix.mean(axis=0)[s]\n",
    "            s_max_coverage = self.coverage_matrix.max(axis=0)[s]\n",
    "            s_fitscore = s_coverage+self.theta*s_score\n",
    "\n",
    "            return (s_score,s_coverage,s_max_coverage,s_fitscore)\n",
    "\n",
    "        if not state:\n",
    "            print(\"Empty state\")\n",
    "            return [random.randint(0,len(self.candidates_strings)-1)]\n",
    "            \n",
    "        rc = state.copy()\n",
    "        s = np.array(state)\n",
    "        s_score, s_coverage, s_max_coverage, s_fitscore = compute_state_arrays(s)\n",
    "               \n",
    "        if len(state) == self.max_size:\n",
    "            print(\"Maximum state size, removing\")\n",
    "            idx = np.argmin(s_fitscore)\n",
    "            del rc[idx]\n",
    "            return rc\n",
    "            \n",
    "        remove_sentence = random.random()<self.prob_to_remove(state)      \n",
    "        # print(\"coverage of {} is {}, remove?{}\".format(state,self.get_state_coverage(state),remove_sentence))\n",
    "        if remove_sentence:             # We decide to remove a sentence from the set\n",
    "            # print(\"Removing\")\n",
    "            probs = softmax(-s_fitscore)\n",
    "            idx = np.random.multinomial(1,probs).argmax()\n",
    "            del rc[idx]                   \n",
    "        else:                           # Add a sentence from the outside\n",
    "            # print(\"Adding\")\n",
    "            anti_state = []\n",
    "            for i in range(len(self.candidates_strings)):\n",
    "                if not i in state:\n",
    "                    anti_state.append(i)\n",
    "            s1 = np.array(anti_state)\n",
    "            s1_score, s1_coverage, s1_max_coverage, s1_fitscore = compute_state_arrays(s1)\n",
    "            # Pick an expert to try and cover\n",
    "            probs = softmax(self.get_expert_coverage(s)*10)         # Coverage is in (0,1), so we use low temprature\n",
    "            expert_to_cover = np.random.multinomial(1,probs).argmax()\n",
    "            probs = softmax(self.coverage_matrix[expert_to_cover][s1]*10)\n",
    "            idx_to_add = np.random.multinomial(1,probs).argmax()\n",
    "            bisect.insort(rc,anti_state[idx_to_add])\n",
    "            \n",
    "        return rc\n",
    "\n",
    "    def temp_schedule(self,i):\n",
    "        schedule = [(5000,0.5), (15000,0.1), (25000,0.01), (35000,0.005), (45000,self.final_temp)]\n",
    "        if i<schedule[0][0]:\n",
    "            return schedule[0][1]\n",
    "        if i>=schedule[-1][0]:\n",
    "            return schedule[-1][1]\n",
    "        for j in range(len(schedule)):\n",
    "            if i<schedule[j+1][0]:\n",
    "                break\n",
    "        start = schedule[j][0]\n",
    "        end = schedule[j+1][0]\n",
    "        start_val = schedule[j][1]\n",
    "        end_val = schedule[j+1][1]\n",
    "\n",
    "        return ((i-start)/(end-start))*(end_val-start_val)+start_val         \n",
    "\n",
    "    def get_scored_permutations(self, k):\n",
    "        n = len(self.candidates)\n",
    "        return [(x,self.get_score(list(x))) for x in itertools.permutations(range(n),k)]\n",
    "\n",
    "    def reset(self):\n",
    "        return max(self.opt_results,key=lambda x:x[1])[0]\n",
    "    \n",
    "        \n",
    "    def simulated_annealing(self, initial_state, clear_prev = False, reset_every = None):\n",
    "        current_temp = self.initial_temp\n",
    "        i = 0\n",
    "        if clear_prev:\n",
    "            self.opt_results = []\n",
    "        if not reset_every:\n",
    "            reset_every = self.reset_every\n",
    "\n",
    "       # Start by initializing the current state with the initial state\n",
    "        current_state = initial_state\n",
    "        curr_score = self.get_score(initial_state)\n",
    "\n",
    "        while current_temp > self.final_temp:\n",
    "            if i % reset_every == 0 and i>0:                \n",
    "                next_cand = self.reset()\n",
    "                print(\"Reset to state: {}\".format(next_cand))\n",
    "            else:\n",
    "                next_cand = self.get_candidate(current_state)            \n",
    "            next_score = self.get_score(next_cand)\n",
    "\n",
    "            # print(\"current score: {} ({}). Candidate score: {} ({})\".format(curr_score,current_state,next_score,next_cand))\n",
    "\n",
    "            # Check if next_cand is best so far\n",
    "            score_diff = next_score - curr_score\n",
    "\n",
    "            # if the new solution is better, accept it\n",
    "            move = False\n",
    "            if score_diff > 0:\n",
    "                move = True\n",
    "            # if the new solution is not better, accept it with a probability of e^(-cost/temp)\n",
    "            else:\n",
    "                print(\"chance to move (from score_diff {}): {}\".format(score_diff,math.exp(score_diff / current_temp)))\n",
    "                move = random.uniform(0, 1) < math.exp(score_diff / current_temp)                    \n",
    "            if move:\n",
    "                current_state = next_cand\n",
    "                curr_score = next_score\n",
    "                self.opt_results.append((current_state,curr_score))\n",
    "            # decrement the temperature\n",
    "            current_temp = self.temp_schedule(i)\n",
    "            i += 1\n",
    "            if i % 1000 == 0:\n",
    "                print(\"i: {}\".format(i))            \n",
    "\n",
    "        return self.reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e195982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_scene(doc,mat=None):\n",
    "    rc = nre.get_scene_from_collection(doc['movie_id'],doc['scene_element'],'s1_lsmdc')\n",
    "    experts = flatten(rc['experts'].values())\n",
    "    sents = list(set(doc['combined_sentences']))\n",
    "    emb_video = vlm.encode_video(doc['movie_id'],doc['scene_element'])\n",
    "    optim = SubsetOptimization(emb_video, experts, sents, coverage_matrix=mat)\n",
    "    rc = optim.simulated_annealing([], reset_every=15000)\n",
    "    coverage = list(zip(optim.experts, optim.get_expert_coverage(rc)))\n",
    "    print(\"Coverage:\")\n",
    "    print(coverage)\n",
    "    print(\"Similarity:\")\n",
    "    print(\"Mean of result: {}\".format(optim.candidates_similarity[rc].mean()))\n",
    "    list(zip(itemgetter(*rc)(optim.candidates_strings),optim.candidates_similarity[rc]))\n",
    "    return list(itemgetter(*rc)(optim.candidates_strings))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc8171",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'FOR doc IN s1_pipeline_results_phase2 RETURN doc'\n",
    "cursor = nre.db.aql.execute(query)\n",
    "all_docs = list(cursor)\n",
    "for doc in all_docs:\n",
    "    mid = doc['movie_id']\n",
    "    elem = doc['scene_element']\n",
    "    rc = nre.get_scene_from_collection(mid,elem,'s1_pipeline_results_final')\n",
    "    if rc:\n",
    "        print(\"Results already exist for {}/{}\".format(mid,elem))\n",
    "        continue\n",
    "    print(\"Going forward with {}/{}\".format(mid,elem))\n",
    "    rc = optimize_scene(doc)\n",
    "    rc_doc = {\n",
    "        'movie_id': mid,\n",
    "        'scene_element': elem,\n",
    "        'sentences': rc\n",
    "    }\n",
    "    query = \"INSERT {} INTO s1_pipeline_results_final\".format(rc_doc)\n",
    "    cursor = nre.db.aql.execute(query)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eff2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7dfe4d185a1b3661f8d189d2dcb52f070789ba26e5d1ea6f8391b638319fa460"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
