{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd4422f0-1ada-4324-8173-2fb89a605b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import bisect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib\n",
    "import subprocess\n",
    "import re\n",
    "import pickle\n",
    "import tempfile\n",
    "import itertools\n",
    "import torch\n",
    "import spacy\n",
    "import amrlib\n",
    "import penman\n",
    "\n",
    "from typing import List, Tuple\n",
    "from operator import itemgetter \n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification\n",
    "# import qgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c79742a6-1df7-40ae-aec8-c3a3960e81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.getcwd()+'/../..')  # /home/gil/dev/NEBULA2/\n",
    "os.chdir(os.getcwd()+'/../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41181f5b-01c9-4ff4-82bf-8819720dc6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nebula_api.nebula_enrichment_api import *\n",
    "from experts.common.RemoteAPIUtility import RemoteAPIUtility\n",
    "from nebula_api.vlmapi import VLM_API\n",
    "from nebula_api.atomic2020.comet_enrichment_api import *\n",
    "from nebula_api.canonisation_api import CANON_API\n",
    "from bart.commonsense_classifier.commonsense_api import CS_API\n",
    "import nebula_api.playground_api as pg_api\n",
    "\n",
    "# from nlp_tools.light_house_generator import LightHouseGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dddd9364-8b09-4c79-9fdc-e9329d40e5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milvus Collection Loaded:  vcomet_mdmmt_embedded_event\n",
      "Milvus Collection Loaded:  vcomet_mdmmt_embedded_place\n",
      "Milvus Collection Loaded:  vcomet_mdmmt_embedded_actions\n",
      "INFO:tensorflow:Restoring parameters from /app/NEBULA2/nebula_api/mdmmt_api/ckpts/vggish_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available class names: ['clip_vit', 'clip_rn', 'mdmmt_max', 'mdmmt_mean', 'mdmmt_legacy']\n",
      "Loading the model roberta-large...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device your are using: cuda:0\n",
      "Loaded model successfully.\n",
      "You can use the API now for testing purposes.\n"
     ]
    }
   ],
   "source": [
    "# with torch.cuda.device(0):\n",
    "nre = NRE_API()\n",
    "api = RemoteAPIUtility()\n",
    "vlm = VLM_API()\n",
    "# mdmmt = mdmmt_api.MDMMT_API()\n",
    "# comet = Comet(\"/app/NEBULA2/nebula_api/atomic2020/comet-atomic_2020_BART\")\n",
    "# with torch.cuda.device(0):\n",
    "ascore = CANON_API()\n",
    "stog = amrlib.load_stog_model(model_dir=\"/app/NEBULA2/models/model_stog\",device='cuda:1')\n",
    "gtos = amrlib.load_gtos_model(model_dir=\"/app/NEBULA2/models/model_gtos\", device='cuda:1')\n",
    "cs_api = CS_API(device_type='gpu', device_id='cuda:0')\n",
    "\n",
    "# Download cola model\n",
    "# cola_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b710fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_trained_model(path):\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        path, \n",
    "        num_labels = 2, \n",
    "        output_attentions = False, # Whether the model returns attentions weights.\n",
    "        output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "        return_dict=False\n",
    "    )\n",
    "    model.to(torch.device('cpu'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# cola_model = ret_trained_model(\"/app/NEBULA2/bart/sentence_correctness_classifier/weights-20220215Feb02\")\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5dcd694-7362-4aa8-89e8-a6107f71ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies = ['Movies/114206952',\n",
    "# 'Movies/114207205',\n",
    "# 'Movies/114207398',\n",
    "# 'Movies/114207499',\n",
    "# 'Movies/114207361',\n",
    "# 'Movies/114207740',\n",
    "# 'Movies/114207908',\n",
    "# 'Movies/114208744',\n",
    "# 'Movies/114206724',\n",
    "# 'Movies/114206548',\n",
    "# 'Movies/114206264']\n",
    "\n",
    "# GPT_LH_COLLECTION = 'nebula_gpt_lsmdc_playground_candidates'\n",
    "GPT_LH_COLLECTION = 'nebula_gpt_lsmdc_experts_playground_candidates'\n",
    "EXPERTS_COLLECTION = 'nebula_comet2020_lsmdc_scored_v02'\n",
    "\n",
    "def get_playground_movies():\n",
    "    return(['Movies/114206816', 'Movies/114206849', 'Movies/114206892', 'Movies/114206952', 'Movies/114206999', 'Movies/114207139', 'Movies/114207205', 'Movies/114207240', 'Movies/114207265', 'Movies/114207324', 'Movies/114207361', 'Movies/114207398', 'Movies/114207441', 'Movies/114207474', 'Movies/114207499', 'Movies/114207550', 'Movies/114207668', 'Movies/114207740', 'Movies/114207781', 'Movies/114207810', 'Movies/114207839', 'Movies/114207908', 'Movies/114207953', 'Movies/114207984', 'Movies/114208064', 'Movies/114208149', 'Movies/114208196', 'Movies/114208338', 'Movies/114208367', 'Movies/114208576', 'Movies/114208637', 'Movies/114208744', 'Movies/114208777', 'Movies/114208820', 'Movies/114206358', 'Movies/114206264', 'Movies/114206337', 'Movies/114206397', 'Movies/114206632', 'Movies/114206597', 'Movies/114206691', 'Movies/114206789', 'Movies/114207184', 'Movies/114206548'])\n",
    "\n",
    "movies = get_playground_movies()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e631f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript\n",
    "from IPython.display import HTML, display\n",
    "import base64\n",
    "\n",
    "\n",
    "def download_video_file(movie, fname='/tmp/video_file.mp4'):    \n",
    "    if os.path.exists(fname):\n",
    "        os.remove(fname)\n",
    "    query = 'FOR doc IN Movies FILTER doc._id == \"{}\" RETURN doc'.format(movie)\n",
    "    cursor = api.db.aql.execute(query)\n",
    "    url_prefix = \"http://ec2-18-159-140-240.eu-central-1.compute.amazonaws.com:7000/\"\n",
    "    url_link = ''\n",
    "    for doc in cursor:\n",
    "        url_link = url_prefix+doc['url_path']\n",
    "        url_link = url_link.replace(\".avi\", \".mp4\")   \n",
    "        print(url_link)\n",
    "        urllib.request.urlretrieve(url_link, fname) \n",
    "    return fname\n",
    "    # video = cv2.VideoCapture(self.temp_file)\n",
    "    # fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    # return(fps, url_link)\n",
    "\n",
    "\n",
    "\n",
    "def read_video_segm(abspath, t_beg, t_end):\n",
    "    cmd = f'ffmpeg -y -ss {t_beg} -i {abspath} -max_muxing_queue_size 9999  -loglevel error -f mp4 -vf scale=\"(floor(112/ih * iw/2))*2:112\"  -c:a copy  -movflags frag_keyframe+empty_moov -t {t_end - t_beg} pipe:1 -nostats -hide_banner -nostdin'\n",
    "    p = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE)\n",
    "    assert p.returncode == 0, cmd\n",
    "    buf = p.stdout\n",
    "    return buf\n",
    "\n",
    "video_id_cnt = 0    \n",
    "class VideoElem:\n",
    "    def __init__(self, fname, t_start=0, t_end=999):\n",
    "        with open(fname, 'rb') as f:\n",
    "            #data = base64.standard_b64encode(f.read())\n",
    "            buf = read_video_segm(fname, t_start, t_end)\n",
    "            data = base64.standard_b64encode(buf)\n",
    "        global video_id_cnt\n",
    "        video_id_cnt += 1\n",
    "        self.video_id_cnt = video_id_cnt\n",
    "        elem = HTML(f\"\"\"\n",
    "            <video id=\"video_{self.video_id_cnt}\" autoplay loop muted>\n",
    "                <source src=\"data:video/mp4;base64,{data.decode('ascii')}\" type=\"video/mp4\">\n",
    "            </video>        \n",
    "        \"\"\")\n",
    "        display(elem)\n",
    "    \n",
    "    def hide(self):\n",
    "        js = f'$(\"#video_{self.video_id_cnt}\").hide()'\n",
    "        display(Javascript(js))\n",
    "        \n",
    "    def show(self):\n",
    "        js = f'$(\"#video_{self.video_id_cnt}\").show()'\n",
    "        display(Javascript(js))\n",
    "\n",
    "    def remove(self):\n",
    "        js = f'$(\"#video_{self.video_id_cnt}\").remove()'\n",
    "        display(Javascript(js))\n",
    "        \n",
    "def mdmmt_video_encode(start_f, stop_f, path='/tmp/video_file.mp4', freq=24):\n",
    "        t_start = start_f//freq\n",
    "        t_end = stop_f//freq\n",
    "        if t_start == t_end:\n",
    "            t_start = t_start - 1\n",
    "        print(\"Start/stop\", t_start, \" \", t_end)\n",
    "        if (t_end - t_start) >= 1:\n",
    "            vemb = mdmmt.encode_video(\n",
    "                mdmmt.vggish_model,  # adio modality\n",
    "                mdmmt.vmz_model,  # video modality\n",
    "                mdmmt.clip_model,  # image modality\n",
    "                mdmmt.model_vid,  # aggregator\n",
    "                path, t_start, t_end)\n",
    "            return(vemb)\n",
    "        else:\n",
    "            print(\"Stage too short\")\n",
    "            return(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2243e402-1e54-466f-bf5a-e930ccc6d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lst): return [x for l in lst for x in l]\n",
    "\n",
    "def compute_batch_scores(video_emb: torch.Tensor, texts: List[str], normalize=True, **kwargs) -> List[float]:    \n",
    "    emb_batch = vlm.encode_text(texts, **kwargs)\n",
    "    if type(emb_batch) == list:\n",
    "        emb_batch = torch.stack(emb_batch,axis=0)\n",
    "    if normalize:\n",
    "        video_emb = video_emb / video_emb.norm(2)\n",
    "        # print(\"normalized video norm: {}\".format(video_emb.norm(2)))\n",
    "        n = (emb_batch * emb_batch).sum(axis=1).sqrt()\n",
    "        emb_batch = emb_batch / n.unsqueeze(1).expand_as(emb_batch)\n",
    "        # print(\"normalized text norms:\")\n",
    "        # for emb in emb_batch:\n",
    "        #     print(emb.norm(2))                        \n",
    "    return (video_emb.unsqueeze(0).expand_as(emb_batch)*emb_batch).sum(dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "def compute_concat_score(image_emb: torch.Tensor, texts: List[str], join_on=',') -> float:\n",
    "    combined_text = \"\"\n",
    "    for t in [x.strip() for x in texts]:\n",
    "        if t[-1]=='.':\n",
    "            t = t[:-1]       \n",
    "        t+=join_on\n",
    "        t+=' '\n",
    "        combined_text+=t\n",
    "    print(\"Combined: \"+combined_text)\n",
    "    return torch.matmul(image_emb,mdmmt.encode_text(combined_text.strip()) )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "992bc58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_concept(c):\n",
    "    exp = re.compile(r\"^([a-zA-z]+)-?(\\d*)$\")\n",
    "    r = exp.match(c)\n",
    "    return r.group(1) if r else c\n",
    "\n",
    "class ConceptManager:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def ground_concept(concept):\n",
    "        return transform_concept(concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5004e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityManager:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "    def similarity(self, c1, c2):\n",
    "        if type(c2) is not list:\n",
    "            c2 = [c2]   \n",
    "        a = self.nlp(c1)\n",
    "        targets = self.nlp(' '.join(c2))\n",
    "        return [a.similarity(x) for x in targets]\n",
    "\n",
    "\n",
    "smanager = SimilarityManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b13d497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = lambda x: np.exp(x)/sum(np.exp(x))\n",
    "\n",
    "class SubsetOptimization:\n",
    "    def __init__(self, video_emb, experts: List, candidates_strings: List[str]):\n",
    "        self.stog = amrlib.load_stog_model(model_dir=\"/app/NEBULA2/models/model_stog\")\n",
    "        self.video_emb = video_emb\n",
    "        self.initial_temp = 10\n",
    "        self.final_temp = .05\n",
    "        self.alpha = 0.01\n",
    "        self.theta = 0.5\n",
    "        self.experts = experts\n",
    "        self.candidates_strings = candidates_strings\n",
    "        self.candidates_amr_strings = self.stog.parse_sents(self.candidates_strings) \n",
    "        self.candidates = self.candidates_amr_strings\n",
    "        self.candidates_amrs = [penman.decode(x) for x in self.candidates_amr_strings]\n",
    "        self.candidates_similarity = compute_batch_scores(self.video_emb, self.candidates_strings)             \n",
    "        self.opt_results = []\n",
    "        self.smanager = SimilarityManager()\n",
    "\n",
    "        self.coverage_matrix = np.zeros([len(self.experts),len(self.candidates)])\n",
    "        self.coverage_matrix[:] = np.nan\n",
    "        for i in range(len(experts)):\n",
    "            for j in range(len(candidates_strings)):\n",
    "                self.coverage_matrix[i][j]=self.concept_amr_similarity(self.experts[i],self.candidates_amrs[j])\n",
    "        self.max_size = int(len(self.experts)*1.5)\n",
    "\n",
    "    def concept_amr_similarity(self, concept, amr):\n",
    "        insts = [ConceptManager.ground_concept(x.target) for x in amr.instances()]\n",
    "        sims = self.smanager.similarity(concept, insts)\n",
    "        return max(sims)\n",
    "\n",
    "    def get_coverage(self,i,j):        \n",
    "        if np.isnan(self.coverage_matrix[i][j]):\n",
    "            self.coverage_matrix[i][j] = self.concept_amr_similarity(self.experts[i],self.candidates_amrs[j])\n",
    "        return self.coverage_matrix[i][j]\n",
    "\n",
    "    def get_expert_coverage(self,state):\n",
    "        return self.coverage_matrix[:,state].max(axis=1)\n",
    "\n",
    "    def get_state_coverage(self,state) -> float:\n",
    "        print(\"State coverage for {}:\".format(state))\n",
    "        print(self.get_expert_coverage(state))\n",
    "        return np.mean(self.get_expert_coverage(state))\n",
    "\n",
    "    # def get_state_coverage(self, state: List[int]) -> float:\n",
    "    #     experts_coverage = [max([self.get_coverage(i,j) for j in state]) for i in range(len(self.experts))]    # A list of partial coverege        \n",
    "    #     return sum(experts_coverage) / len(self.experts)\n",
    "\n",
    "    def get_cost(self, state: List[int]) -> float:\n",
    "        if not state:\n",
    "            return 0\n",
    "        coverage_score = self.get_state_coverage(state)           \n",
    "        similarity_score = self.candidates_similarity[state].mean().item()\n",
    "        return -(coverage_score + self.theta*similarity_score)\n",
    "\n",
    "    # state here is assumed (and guaranteed on return) to be -sorted-\n",
    "    def get_candidate(self, state: List[int]) -> List[int]:\n",
    "        def compute_state_arrays(s):\n",
    "            print(\"Computing arrays for state: \")\n",
    "            print(s)\n",
    "            s_score = self.candidates_similarity[s]\n",
    "            s_coverage = self.coverage_matrix.mean(axis=0)[s]\n",
    "            s_max_coverage = self.coverage_matrix.max(axis=0)[s]\n",
    "            s_fitscore = s_coverage+self.theta*s_score\n",
    "\n",
    "            return (s_score,s_coverage,s_max_coverage,s_fitscore)\n",
    "\n",
    "        if not state:\n",
    "            print(\"Empty state\")\n",
    "            return [random.randint(0,len(self.candidates_strings)-1)]\n",
    "            \n",
    "        rc = state.copy()\n",
    "        s = np.array(state)\n",
    "        s_score, s_coverage, s_max_coverage, s_fitscore = compute_state_arrays(s)\n",
    "               \n",
    "        if len(state) == self.max_size:\n",
    "            print(\"Maximum state size, removing\")\n",
    "            idx = np.argmin(s_fitscore)\n",
    "            del rc[idx]\n",
    "            return rc\n",
    "            \n",
    "        remove_sentence = random.random()<self.get_state_coverage(state)        \n",
    "        print(\"coverage of {} is {}, remove?{}\".format(state,self.get_state_coverage(state),remove_sentence))\n",
    "        if remove_sentence:             # We decide to remove a sentence from the set\n",
    "            print(\"Removing\")\n",
    "            probs = softmax(-s_fitscore)\n",
    "            idx = np.random.multinomial(1,probs).argmax()\n",
    "            del rc[idx]                   \n",
    "        else:                           # Add a sentence from the outside\n",
    "            print(\"Adding\")\n",
    "            anti_state = []\n",
    "            for i in range(len(self.candidates_strings)):\n",
    "                if not i in state:\n",
    "                    anti_state.append(i)\n",
    "            s1 = np.array(anti_state)\n",
    "            s1_score, s1_coverage, s1_max_coverage, s1_fitscore = compute_state_arrays(s1)\n",
    "            # Pick an expert to try and cover\n",
    "            probs = softmax(self.get_expert_coverage(s)*10)         # Coverage is in (0,1), so we use low temprature\n",
    "            expert_to_cover = np.random.multinomial(1,probs).argmax()\n",
    "            probs = softmax(self.coverage_matrix[expert_to_cover][s1]*10)\n",
    "            idx_to_add = np.random.multinomial(1,probs).argmax()\n",
    "            bisect.insort(rc,anti_state[idx_to_add])\n",
    "            \n",
    "        return rc\n",
    "\n",
    "\n",
    "\n",
    "    def get_scored_permutations(self, k):\n",
    "        n = len(self.candidates)\n",
    "        return [(x,self.get_cost(list(x))) for x in itertools.permutations(range(n),k)]\n",
    "        \n",
    "    def simulated_annealing(self, initial_state):\n",
    "        self.opt_results = []\n",
    "        current_temp = self.initial_temp\n",
    "\n",
    "       # Start by initializing the current state with the initial state\n",
    "        current_state = initial_state\n",
    "\n",
    "        while current_temp > self.final_temp:\n",
    "            next_cand = self.get_candidate(current_state)\n",
    "\n",
    "            print(\"current cost: {} ({}). Candidate cost: {} ({})\".format(self.get_cost(current_state),current_state,self.get_cost(next_cand),next_cand))\n",
    "\n",
    "            # Check if next_cand is best so far\n",
    "            cost_diff = self.get_cost(current_state) - self.get_cost(next_cand)\n",
    "\n",
    "            # if the new solution is better, accept it\n",
    "            if cost_diff > 0:\n",
    "                current_state = next_cand\n",
    "            # if the new solution is not better, accept it with a probability of e^(-cost/temp)\n",
    "            else:\n",
    "                print(\"chance to move: {}\".format(math.exp(cost_diff / current_temp)))\n",
    "                if random.uniform(0, 1) < math.exp(cost_diff / current_temp):\n",
    "                    current_state = next_cand\n",
    "            # decrement the temperature\n",
    "            current_temp -= self.alpha\n",
    "            self.opt_results.append(-self.get_cost(current_state))\n",
    "\n",
    "        return current_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad7bd7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get a list of 1-item dictionaries, return a list of the values\n",
    "'''\n",
    "\n",
    "def rearrange_concepts(concepts, max_experts=10):\n",
    "    return concepts[:max_experts]\n",
    "\n",
    "def permute_sentence(pen, concepts, **kwargs):    \n",
    "    def replace_instance(g: penman.Graph, changes: List[tuple[int,str]]) -> penman.Graph :\n",
    "        amr_copy = penman.Graph(triples=g.triples, epidata=g.epidata)\n",
    "        for (i,val) in changes:\n",
    "            b = list(amr_copy.triples[i])\n",
    "            b[2] = val\n",
    "            amr_copy.triples[i] = tuple(b)\n",
    "        return amr_copy\n",
    "\n",
    "    concepts = {k: rearrange_concepts(v, **kwargs) for (k,v) in concepts.items()}    \n",
    "    insts_list = []\n",
    "    rc = []\n",
    "    concept_classes = []\n",
    "    dims = []\n",
    "    for i,triplet in enumerate(pen.triples):\n",
    "        if triplet[1] == ':instance':\n",
    "            entity_class = ascore.get_class_of_entity(transform_concept(triplet[2]))\n",
    "            concept_class = concepts[entity_class] if entity_class in concepts.keys() else []\n",
    "            if triplet[2] not in concept_class:\n",
    "                concept_class.append(triplet[2])\n",
    "            insts_list.append((i,triplet, entity_class))\n",
    "            dims.append(range(len(concept_class)))\n",
    "            concept_classes.append(concept_class)\n",
    "    prods = itertools.product(*dims)\n",
    "    for cand in prods:        \n",
    "        changes = [(insts_list[i][0],concept_classes[i][d]) for (i,d) in enumerate(cand)]\n",
    "        rc.append(replace_instance(pen,changes))\n",
    "    \n",
    "    return rc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7005bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_variables(pen, prefix='n_'):\n",
    "    new_triples = []\n",
    "    for t in pen.triples:\n",
    "        triple = list(t)\n",
    "        if triple[0] in pen.variables():\n",
    "            triple[0] = prefix+triple[0]\n",
    "        if triple[2] in pen.variables():\n",
    "            triple[2] = prefix+triple[2]\n",
    "        new_triples.append(tuple(triple))\n",
    "    amr_copy = penman.Graph(triples=new_triples)\n",
    "    return amr_copy            \n",
    "    \n",
    "\n",
    "def combine_place(base_amr, place_amr):\n",
    "    place_copy = rename_variables(place_amr)\n",
    "    combined_triples = base_amr.triples + place_copy.triples \n",
    "    combined_triples.append(tuple([base_amr.top, ':location', place_copy.top]))\n",
    "    return penman.Graph(triples=combined_triples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cefbc1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_lh(mid, elem):\n",
    "    rc = nre.get_scene_from_collection(mid,elem,GPT_LH_COLLECTION)\n",
    "    return rc['combined']\n",
    "def get_experts(mid, elem):\n",
    "    rc = nre.get_scene_from_collection(mid,elem,EXPERTS_COLLECTION)\n",
    "    return rc['experts'] if rc else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa4d3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = []\n",
    "for mid in get_playground_movies():\n",
    "    movie_info = api.get_movie_info(mid)\n",
    "    fps = movie_info['fps']\n",
    "    for i,elem_range in enumerate(movie_info['scene_elements']):\n",
    "        if elem_range[1]-elem_range[0]+1 < fps:\n",
    "            continue\n",
    "        if get_experts(mid,i):\n",
    "            movies.append((mid,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4037c4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Movies/114206952', 1),\n",
       " ('Movies/114207324', 0),\n",
       " ('Movies/114207908', 0),\n",
       " ('Movies/114208149', 2),\n",
       " ('Movies/114208196', 1),\n",
       " ('Movies/114208338', 0),\n",
       " ('Movies/114208576', 0),\n",
       " ('Movies/114208744', 0),\n",
       " ('Movies/114208744', 2),\n",
       " ('Movies/114206337', 0),\n",
       " ('Movies/114206337', 1),\n",
       " ('Movies/114206548', 0),\n",
       " ('Movies/114206548', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6946254a",
   "metadata": {},
   "source": [
    "0: ('Movies/114206952', 1)\n",
    "  Replacemanet:\n",
    "    ballroom -> bow\n",
    "  \n",
    "  Addition:\n",
    "    \"A group of people arrives at the upper level of the ships ballroom\" -> \"A group of people in suits arrives at the upper level of the ships ballroom where a skipper stands\"\n",
    "      (MDMMT score falls)\n",
    "\n",
    "1: ('Movies/114207324', 0)\n",
    "  Replacement:\n",
    "    man -> nobleman\n",
    "    \n",
    "  Addition:\n",
    "\n",
    "    \"A man in a dress bows his head as the gentry pass by in the royal court\" -> \"A man in a grey dress standing by a window with candles and a vase of flowers bows his head as the gentry pass by in the royal court\"\n",
    "    \"A man and a woman facing each other...\"\n",
    "    (MDMMT score falls. These are not attributes)\n",
    "    (addition of attribute \"grey\" works)\n",
    "\n",
    "2: \n",
    "  Replacement:\n",
    "    suit -> helmet, shield\n",
    "    dress -> ?\n",
    "    man -> knight, warrior, soldier\n",
    "    noble -> knight, warrior, soldier\n",
    "\n",
    "  Addition:\n",
    "    \"A man in a suit and a woman in a dress protect the nobles behind them in the roman arena\" -> \"A man in a suit and a woman in a dress protect the three nobles behind them in the roman arena\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9d6aafce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3307741 , 0.3080391 , 0.34513435], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_batch_scores(emb_image,[\"A man in a helmet and a woman in a dress facing each other protect the nobles behind them in the roman arena\", \"A man in a suit and a woman in a dress protect the nobles behind them in the roman arena\", \"A warrior in a helmet and a woman in a dress protect the nobles behind them in the roman arena\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6337b2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ec2-18-159-140-240.eu-central-1.compute.amazonaws.com:7000/static/development/0025_THE_LORD_OF_THE_RINGS_THE_RETURN_OF_THE_KING_02_55_46_515-02_55_51_946.mp4\n",
      "Movie info: {'arango_id': 'Movies/114207908', 'description': '0025_THE_LORD_OF_THE_RINGS_THE_RETURN_OF_THE_KING_02_55_46_515-02_55_51_946', 'fps': 23, 'width': 1920, 'height': 1080, 'last frame': 300, 'movie_id': 'f9305a676703419bb958d2c44454293f', 'mdfs': [[2, 57, 112], [116, 122, 129]], 'scene_elements': [[0, 114], [114, 131]]}\n",
      "fn path: /tmp/video_file.mp4\n"
     ]
    }
   ],
   "source": [
    "# mid = 'Movies/114208338' # 'Movies/114208338'\n",
    "mid, elem = movies[2]\n",
    "movie_info = api.get_movie_info(mid)\n",
    "emb_image = vlm.encode_video(mid,elem,class_name='mdmmt_mean')\n",
    "data = nre.get_groundings_from_db(mid,elem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b87e95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = nre.get_scene_from_collection(mid,elem,GPT_LH_COLLECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "11adcba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' A man in a suit and a woman in a dress face off with the enemy bravely in a medieval war party',\n",
       " ['A man in a suit and a woman in a dress',\n",
       "  'face off with the enemy bravely',\n",
       "  'in a medieval war party'])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc['combined'][5], rc['source'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "54ddcdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to evaluate the input for the model..\n"
     ]
    }
   ],
   "source": [
    "lh = get_gpt_lh(mid,elem)\n",
    "experts = get_experts(mid,elem)\n",
    "scores = compute_batch_scores(emb_image,lh)\n",
    "cs_scores = cs_api.get_sentences_score(lh)\n",
    "# First remove all nonsensical sentences (<0.5), then take 5 best by mdmmt\n",
    "scored_sentences = [x for x in sorted(zip(lh,scores,cs_scores),key=lambda x: -x[2]) if x[2]>0.5]\n",
    "scored_sentences = sorted(scored_sentences,key=lambda x: -x[1])[:5]\n",
    "bases = list(list(zip(*scored_sentences))[0])\n",
    "# bases[0] = \"A man in a suit and tie removes the envelope from the owl's mouth in the government capitol\"\n",
    "# bases[1] = 'A man in a suit and tie closes his notes in the government  capitol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "51a56fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([' A man in a suit and a woman in a dress face off with the enemy bravely in the roman arena',\n",
       "  ' A man in a suit and a woman provide support to the knights in the roman arena',\n",
       "  ' A man in a suit and a woman in a dress protect the nobles behind them in the roman arena',\n",
       "  ' A man in a suit and a woman in a dress face off with the enemy bravely in a medieval war party',\n",
       "  ' A man in a suit and a woman in a dress protect the nobles behind him on a medieval battlefield'],\n",
       " {'person': ['warrior', 'blonde', 'lady', 'soldier', 'knight', 'WHO', 'blond'],\n",
       "  'artifact': ['helmet', 'shield', 'facing', 'spear', 'weapon', 'watch'],\n",
       "  'body_part': ['arm', 'shoulder', 'behind'],\n",
       "  'attribute': ['background', 'three'],\n",
       "  'location': ['left']},\n",
       " [' A man in a suit and a woman in a dress face off with the enemy bravely outside mordor',\n",
       "  ' A man in a suit and a woman in a dress protect the nobles behind him outside of Mordor',\n",
       "  ' A man in a suit and a woman in a dress confront his enemies with a vengeance outside of Mordor',\n",
       "  ' A man in a suit and a woman in a dress leads his army to victory outside of mordor',\n",
       "  ' A man in a suit and a woman provide support to the knights outside of Mordor',\n",
       "  ' A man in a suit and a woman in a dress face off with the enemy bravely in a medieval war party',\n",
       "  ' A man in a suit and a woman in a dress protect the nobles behind him in a medieval war party',\n",
       "  ' A man in a suit and a woman in a dress confront his enemies with a vengeance in a medieval war party',\n",
       "  ' A man in a suit and a woman in a dress leads his army to victory in a medieval war party',\n",
       "  ' A man in a suit and a woman in a dress provide support to the knights in a medieval war party',\n",
       "  ' A man in a suit and a woman in a dress face off with the enemy bravely on a medieval battlefield',\n",
       "  ' A man in a suit and a woman in a dress protect the nobles behind him on a medieval battlefield',\n",
       "  ' A man in a suit and a woman in a dress confront his enemies with a vengeance on a medieval battlefield',\n",
       "  ' A man in a suit and a woman in a dress leads his army to victory on a medieval battlefield',\n",
       "  ' A man in a suit and a woman in a dress provides support to the knights on a medieval battlefield',\n",
       "  ' A man in a suit and a woman in a dress face off with the enemy bravely in the roman arena',\n",
       "  ' A man in a suit and a woman in a dress protect the nobles behind them in the roman arena',\n",
       "  ' A man in a suit and a woman in a dress confront his enemies with a vengeance in the roman arena',\n",
       "  ' A man in a suit and a woman in a dress leads his army to victory in the roman arena',\n",
       "  ' A man in a suit and a woman provide support to the knights in the roman arena',\n",
       "  ' A man in a suit and a woman in a dress face off with the enemy bravely at a medieval tournament',\n",
       "  ' A man in a suit and a woman in a dress protect the nobles behind him at a medieval tournament',\n",
       "  ' A man in a suit and a woman in a dress confront his enemies with a vengeance at a medieval tournament',\n",
       "  ' A man in a suit and a woman in a dress leads his army to victory at a medieval tournament',\n",
       "  ' A man in a suit and a woman in a dress provide support to the knights at a medieval tournament'])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bases, experts, lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "39523f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_base_amrs = [penman.decode(x) for x in stog.parse_sents(bases)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe78ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = []\n",
    "for base_amr in all_base_amrs:\n",
    "    rc.extend(permute_sentence(base_amr,experts, max_experts=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a65ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7528c42d-c416-4490-9f78-19ebdd54b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "all_cs_scores = []\n",
    "all_scores = []\n",
    "all_sentences = []\n",
    "while i < len(rc):\n",
    "    print(\"i is {}\".format(i))\n",
    "    sentences = gtos.generate([penman.encode(x) for x in rc[i:i+3500]])[0]\n",
    "    # inputs = tokenizer.batch_encode_plus(sentences,padding=True,return_tensors=\"pt\")\n",
    "    # cola_scores = cola_model(**inputs).logits.softmax(dim=1)[:,1].tolist()\n",
    "    # cola_scores = cola_model(**inputs)[0].softmax(dim=1)[:,1].tolist()\n",
    "    cs_scores = cs_api.get_sentences_score(sentences)\n",
    "    scores = compute_batch_scores(emb_image,sentences,class_name='mdmmt_mean')\n",
    "    all_sentences.extend(sentences)\n",
    "    all_cs_scores.extend(cs_scores)\n",
    "    all_scores.extend(scores)\n",
    "    i += 3500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd4a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/app/saved_synth_sentences.pickle','wb') as f:\n",
    "    pickle.dump((all_sentences,all_scores,all_cs_scores),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c6fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = list(reversed(sorted(zip(all_sentences,all_scores),key=lambda x: x[1])))\n",
    "z = list(reversed(sorted([x for i,x in enumerate(zip(all_sentences,all_cs_scores,all_scores)) if x[1] > 0.98],key=lambda x: x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dadd511",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = list(reversed(sorted(z,key = lambda x:x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e91eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1[:20]\n",
    "# len(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f573d282-57ee-421c-b5f7-271a9f82a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.argpartition(all_scores, -10)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b36b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(all_sentences[i], all_scores[i]) for i in ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef52a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "amr = all_base_amrs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa604eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "[amr] = [penman.decode(x) for x in stog.parse_sents([\"A man in a suit and tie removes the envelope from the owl's mouth in the government capitol\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6d762a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edb948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = penman.layout.configure(amr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.node[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa56fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7dfe4d185a1b3661f8d189d2dcb52f070789ba26e5d1ea6f8391b638319fa460"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
