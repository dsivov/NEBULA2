{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd4422f0-1ada-4324-8173-2fb89a605b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import bisect\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib\n",
    "import subprocess\n",
    "import re\n",
    "import tempfile\n",
    "import itertools\n",
    "import torch\n",
    "import spacy\n",
    "import amrlib\n",
    "import penman\n",
    "import openai\n",
    "\n",
    "from typing import List, Tuple\n",
    "from operator import itemgetter \n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification\n",
    "# import qgrid\n",
    "\n",
    "BASE_DIR = os.path.abspath(os.getcwd()+'/../..')  # /home/gil/dev/NEBULA2/\n",
    "os.chdir(os.getcwd()+'/../..')\n",
    "OPENAI_API_KEY=''\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "from nebula_api.nebula_enrichment_api import *\n",
    "from experts.common.RemoteAPIUtility import RemoteAPIUtility\n",
    "from nebula_api.vlmapi import VLM_API\n",
    "from nebula_api.atomic2020.comet_enrichment_api import *\n",
    "from nebula_api.canonisation_api import CANON_API\n",
    "import nebula_api.playground_api as pg_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dddd9364-8b09-4c79-9fdc-e9329d40e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nre = NRE_API()\n",
    "api = RemoteAPIUtility()\n",
    "# vlm = VLM_API()\n",
    "# ascore = CANON_API()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2243e402-1e54-466f-bf5a-e930ccc6d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lst): return [x for l in lst for x in l]\n",
    "\n",
    "def compute_batch_scores(video_emb: torch.Tensor, texts: List[str], normalize=True, **kwargs) -> List[float]:    \n",
    "    emb_batch = vlm.encode_text(texts, **kwargs)\n",
    "    if type(emb_batch) == list:\n",
    "        emb_batch = torch.stack(emb_batch,axis=0)\n",
    "    if normalize:\n",
    "        video_emb = (video_emb / video_emb.norm(2)).squeeze()           # This should be done in vlm\n",
    "        # print(\"normalized video norm: {}\".format(video_emb.norm(2)))\n",
    "        n = (emb_batch * emb_batch).sum(axis=1).sqrt()\n",
    "        emb_batch = emb_batch / n.unsqueeze(1).expand_as(emb_batch)\n",
    "        # print(\"normalized text norms:\")\n",
    "        # for emb in emb_batch:\n",
    "        #     print(emb.norm(2))                        \n",
    "    return (video_emb.unsqueeze(0).expand_as(emb_batch)*emb_batch).sum(dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "def compute_concat_score(image_emb: torch.Tensor, texts: List[str], join_on=',') -> float:\n",
    "    combined_text = \"\"\n",
    "    for t in [x.strip() for x in texts]:\n",
    "        if t[-1]=='.':\n",
    "            t = t[:-1]       \n",
    "        t+=join_on\n",
    "        t+=' '\n",
    "        combined_text+=t\n",
    "    print(\"Combined: \"+combined_text)\n",
    "    return torch.matmul(image_emb,mdmmt.encode_text(combined_text.strip()) )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5d7785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_model=\"davinci:ft-personal:fusion-2022-03-29-21-07-19\"\n",
    "fusion_prompt_template=\"Original: {}\\nCandidates: {}\\n\\n###\\n\\n\"\n",
    "\n",
    "def gpt_execute(prompt_template, *args, **kwargs):            \n",
    "    prompt = prompt_template.format(*args)   \n",
    "    response = openai.Completion.create(prompt=prompt, max_tokens=256, **kwargs)   \n",
    "    return response\n",
    "\n",
    "def gpt_fusion_ft(base, experts, **kwargs):\n",
    "    rc = gpt_execute(fusion_prompt_template, base, '; '.join(experts), stop=[\"\\n\"], model=fusion_model, **kwargs)\n",
    "    return [x['text'].strip() for x in rc['choices']]\n",
    "\n",
    "\n",
    "def gpt_batch_fusion(base, all_expert_combs, **kwargs):    \n",
    "    prompts = [fusion_prompt_template.format(base,'; '.join(exp)) for exp in all_expert_combs]\n",
    "    rc = openai.Completion.create(prompt=prompts, max_tokens=256, stop=[\"\\n\"], model=fusion_model, **kwargs)\n",
    "    return [x['text'].strip() for x in rc['choices']]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bb5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PROMPT_NUM = 20\n",
    "\n",
    "def gpt_process_fusion(base, all_experts, **kwargs):\n",
    "    rc = []\n",
    "    flattened_experts = flatten(all_experts.values())\n",
    "    print(\"Total number of experts: {}\".format(len(flattened_experts)))\n",
    "    exp_combinations = [list(x) for x in list(itertools.combinations(flattened_experts,3)) + list(itertools.combinations(flattened_experts,2))]\n",
    "    # exp_combinations = [list(x) for x in list(itertools.combinations(flattened_experts,2))]\n",
    "    print(\"Total number of expert combinations: {}\".format(len(exp_combinations)))\n",
    "    chunked_experts=[exp_combinations[i:i + MAX_PROMPT_NUM] for i in range(0, len(exp_combinations), MAX_PROMPT_NUM)]\n",
    "    for experts in chunked_experts:\n",
    "        # print('\\n\\n--------------\\n\\n')\n",
    "        # print(experts)\n",
    "        rc.extend(gpt_batch_fusion(base,experts, **kwargs))\n",
    "    return rc\n",
    "\n",
    "def process_scene(doc, max_sentences=10, **kwargs):\n",
    "    mid = doc['movie_id']\n",
    "    elem = doc['scene_element']\n",
    "    rc = nre.get_scene_from_collection(mid,elem,'s1_pipeline_results_phase2')\n",
    "    if rc:\n",
    "        print(\"Results already exist for {}/{}\".format(mid,elem))\n",
    "        return\n",
    "    print(\"Going forward with {}/{}\".format(mid,elem))\n",
    "    done = False\n",
    "    while not done:\n",
    "        try:\n",
    "            rc = gpt_process_fusion(doc['base'],doc['experts'], **kwargs)\n",
    "            done=True\n",
    "        except:\n",
    "            print('Error, re-trying')\n",
    "    rc_doc = {\n",
    "        'movie_id': doc['movie_id'],\n",
    "        'scene_element': doc['scene_element'],\n",
    "        'combined_sentences': rc\n",
    "    }\n",
    "    query = \"INSERT {} INTO s1_pipeline_results_phase2\".format(rc_doc)\n",
    "    cursor = nre.db.aql.execute(query)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f006a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'FOR doc IN s1_lsmdc RETURN doc'\n",
    "cursor = nre.db.aql.execute(query)\n",
    "all_docs = list(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b2d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_scene(all_docs[1],n=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7dfe4d185a1b3661f8d189d2dcb52f070789ba26e5d1ea6f8391b638319fa460"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
